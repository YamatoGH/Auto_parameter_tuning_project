{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('{\\n  \"名前\": \"AI助手\",\\n  \"バージョン\": \"1.0\",\\n  \"言語\": [\"日本語\", \"英語\", \"その他の言語\"],\\n  \"専門分野\": [\\n    \"情報提供\",\\n    \"質問応答\",\\n    \"学習支援\",\\n    \"アドバイス\"\\n  ],\\n  \"特徴\": {\\n    \"24時間利用可能\": true,\\n    \"感情を持たない\": true,\\n    \"データ更新\": \"2023年10月\"\\n  },\\n  \"目的\": \"ユーザーの質問に答え、情報を提供すること\"\\n}', [{'role': 'user', 'content': 'あなたの自己紹介をJSON形式でしてください'}, {'role': 'assistant', 'content': '{\\n  \"名前\": \"AI助手\",\\n  \"バージョン\": \"1.0\",\\n  \"言語\": [\"日本語\", \"英語\", \"その他の言語\"],\\n  \"専門分野\": [\\n    \"情報提供\",\\n    \"質問応答\",\\n    \"学習支援\",\\n    \"アドバイス\"\\n  ],\\n  \"特徴\": {\\n    \"24時間利用可能\": true,\\n    \"感情を持たない\": true,\\n    \"データ更新\": \"2023年10月\"\\n  },\\n  \"目的\": \"ユーザーの質問に答え、情報を提供すること\"\\n}'}])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import json\n",
    "\n",
    "from run_auto_tuning_lgbm import get_parameters_from_json, run_auto_tuning_lgbm\n",
    "from generate_LLM_response import get_response_from_llm\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データロード\n",
    "data = fetch_california_housing()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = data.target\n",
    "\n",
    "# データ分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0th trial\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000096 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1838\n",
      "[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 2.071947\n",
      "\n",
      "[{'learning_rate': [0.01, 0.5, 1], 'n_estimators': [50, 250, 500], 'max_depth': [5, 20, 50]}]\n",
      "\n",
      "        Best parameters: {'learning_rate': 0.01, 'max_depth': 20, 'n_estimators': 500}\n",
      "        RMSE: 0.2005144446021315\n",
      "        \n",
      "\n",
      "1th trial\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000349 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1838\n",
      "[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 2.071947\n",
      "\n",
      "[{'learning_rate': [0.01, 0.5, 1], 'n_estimators': [50, 250, 500], 'max_depth': [5, 20, 50]}, {'learning_rate': [0.02, 0.04, 0.06, 0.08], 'n_estimators': [300, 350, 400, 450, 500, 550], 'max_depth': [15, 16, 17, 18, 19, 20, 21, 22, 23, 24]}]\n",
      "\n",
      "        Best parameters: {'learning_rate': 0.08, 'max_depth': 16, 'n_estimators': 550}\n",
      "        RMSE: 0.07113091091899747\n",
      "        \n",
      "\n",
      "2th trial\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000272 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1838\n",
      "[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 2.071947\n",
      "\n",
      "[{'learning_rate': [0.01, 0.5, 1], 'n_estimators': [50, 250, 500], 'max_depth': [5, 20, 50]}, {'learning_rate': [0.02, 0.04, 0.06, 0.08], 'n_estimators': [300, 350, 400, 450, 500, 550], 'max_depth': [15, 16, 17, 18, 19, 20, 21, 22, 23, 24]}, {'learning_rate': [0.05, 0.060000000000000005, 0.07, 0.08000000000000002, 0.09000000000000001], 'n_estimators': [500, 550], 'max_depth': [14, 15, 16]}]\n",
      "\n",
      "        Best parameters: {'learning_rate': 0.08000000000000002, 'max_depth': 16, 'n_estimators': 550}\n",
      "        RMSE: 0.07113091091899704\n",
      "        \n",
      "\n",
      "3th trial\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000278 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1838\n",
      "[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 2.071947\n",
      "\n",
      "[{'learning_rate': [0.01, 0.5, 1], 'n_estimators': [50, 250, 500], 'max_depth': [5, 20, 50]}, {'learning_rate': [0.02, 0.04, 0.06, 0.08], 'n_estimators': [300, 350, 400, 450, 500, 550], 'max_depth': [15, 16, 17, 18, 19, 20, 21, 22, 23, 24]}, {'learning_rate': [0.05, 0.060000000000000005, 0.07, 0.08000000000000002, 0.09000000000000001], 'n_estimators': [500, 550], 'max_depth': [14, 15, 16]}, {'learning_rate': [0.06, 0.06999999999999999, 0.07999999999999999, 0.08999999999999998, 0.09999999999999998], 'n_estimators': [600, 650], 'max_depth': [17, 18, 19, 20, 21]}]\n",
      "\n",
      "        Best parameters: {'learning_rate': 0.07999999999999999, 'max_depth': 17, 'n_estimators': 650}\n",
      "        RMSE: 0.0623091735874655\n",
      "        \n",
      "\n",
      "4th trial\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000194 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1838\n",
      "[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 2.071947\n",
      "\n",
      "[{'learning_rate': [0.01, 0.5, 1], 'n_estimators': [50, 250, 500], 'max_depth': [5, 20, 50]}, {'learning_rate': [0.02, 0.04, 0.06, 0.08], 'n_estimators': [300, 350, 400, 450, 500, 550], 'max_depth': [15, 16, 17, 18, 19, 20, 21, 22, 23, 24]}, {'learning_rate': [0.05, 0.060000000000000005, 0.07, 0.08000000000000002, 0.09000000000000001], 'n_estimators': [500, 550], 'max_depth': [14, 15, 16]}, {'learning_rate': [0.06, 0.06999999999999999, 0.07999999999999999, 0.08999999999999998, 0.09999999999999998], 'n_estimators': [600, 650], 'max_depth': [17, 18, 19, 20, 21]}, {'learning_rate': [0.07, 0.08, 0.09], 'n_estimators': [700, 750], 'max_depth': [18, 19, 20, 21]}]\n",
      "\n",
      "        Best parameters: {'learning_rate': 0.08, 'max_depth': 18, 'n_estimators': 750}\n",
      "        RMSE: 0.05478191028668067\n",
      "        \n",
      "\n",
      "5th trial\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000307 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1838\n",
      "[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 2.071947\n",
      "\n",
      "[{'learning_rate': [0.01, 0.5, 1], 'n_estimators': [50, 250, 500], 'max_depth': [5, 20, 50]}, {'learning_rate': [0.02, 0.04, 0.06, 0.08], 'n_estimators': [300, 350, 400, 450, 500, 550], 'max_depth': [15, 16, 17, 18, 19, 20, 21, 22, 23, 24]}, {'learning_rate': [0.05, 0.060000000000000005, 0.07, 0.08000000000000002, 0.09000000000000001], 'n_estimators': [500, 550], 'max_depth': [14, 15, 16]}, {'learning_rate': [0.06, 0.06999999999999999, 0.07999999999999999, 0.08999999999999998, 0.09999999999999998], 'n_estimators': [600, 650], 'max_depth': [17, 18, 19, 20, 21]}, {'learning_rate': [0.07, 0.08, 0.09], 'n_estimators': [700, 750], 'max_depth': [18, 19, 20, 21]}, {'learning_rate': [0.07, 0.08, 0.09], 'n_estimators': [760, 780], 'max_depth': [19, 20, 21, 22]}]\n",
      "\n",
      "        Best parameters: {'learning_rate': 0.08, 'max_depth': 21, 'n_estimators': 760}\n",
      "        RMSE: 0.05379652395073347\n",
      "        \n",
      "\n",
      "6th trial\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000279 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1838\n",
      "[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 2.071947\n",
      "\n",
      "[{'learning_rate': [0.01, 0.5, 1], 'n_estimators': [50, 250, 500], 'max_depth': [5, 20, 50]}, {'learning_rate': [0.02, 0.04, 0.06, 0.08], 'n_estimators': [300, 350, 400, 450, 500, 550], 'max_depth': [15, 16, 17, 18, 19, 20, 21, 22, 23, 24]}, {'learning_rate': [0.05, 0.060000000000000005, 0.07, 0.08000000000000002, 0.09000000000000001], 'n_estimators': [500, 550], 'max_depth': [14, 15, 16]}, {'learning_rate': [0.06, 0.06999999999999999, 0.07999999999999999, 0.08999999999999998, 0.09999999999999998], 'n_estimators': [600, 650], 'max_depth': [17, 18, 19, 20, 21]}, {'learning_rate': [0.07, 0.08, 0.09], 'n_estimators': [700, 750], 'max_depth': [18, 19, 20, 21]}, {'learning_rate': [0.07, 0.08, 0.09], 'n_estimators': [760, 780], 'max_depth': [19, 20, 21, 22]}, {'learning_rate': [0.07, 0.08, 0.09], 'n_estimators': [700, 710, 720, 730, 740, 750, 760, 770, 780, 790], 'max_depth': [20, 21, 22]}]\n",
      "\n",
      "        Best parameters: {'learning_rate': 0.08, 'max_depth': 21, 'n_estimators': 760}\n",
      "        RMSE: 0.05379652395073347\n",
      "        \n",
      "\n",
      "7th trial\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000292 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1838\n",
      "[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 2.071947\n",
      "\n",
      "[{'learning_rate': [0.01, 0.5, 1], 'n_estimators': [50, 250, 500], 'max_depth': [5, 20, 50]}, {'learning_rate': [0.02, 0.04, 0.06, 0.08], 'n_estimators': [300, 350, 400, 450, 500, 550], 'max_depth': [15, 16, 17, 18, 19, 20, 21, 22, 23, 24]}, {'learning_rate': [0.05, 0.060000000000000005, 0.07, 0.08000000000000002, 0.09000000000000001], 'n_estimators': [500, 550], 'max_depth': [14, 15, 16]}, {'learning_rate': [0.06, 0.06999999999999999, 0.07999999999999999, 0.08999999999999998, 0.09999999999999998], 'n_estimators': [600, 650], 'max_depth': [17, 18, 19, 20, 21]}, {'learning_rate': [0.07, 0.08, 0.09], 'n_estimators': [700, 750], 'max_depth': [18, 19, 20, 21]}, {'learning_rate': [0.07, 0.08, 0.09], 'n_estimators': [760, 780], 'max_depth': [19, 20, 21, 22]}, {'learning_rate': [0.07, 0.08, 0.09], 'n_estimators': [700, 710, 720, 730, 740, 750, 760, 770, 780, 790], 'max_depth': [20, 21, 22]}, {'learning_rate': [0.07, 0.08, 0.09], 'n_estimators': [740, 750, 760, 770, 780, 790], 'max_depth': [20, 21, 22]}]\n",
      "\n",
      "        Best parameters: {'learning_rate': 0.08, 'max_depth': 21, 'n_estimators': 760}\n",
      "        RMSE: 0.05379652395073347\n",
      "        \n",
      "\n",
      "8th trial\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000315 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1838\n",
      "[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 2.071947\n",
      "\n",
      "[{'learning_rate': [0.01, 0.5, 1], 'n_estimators': [50, 250, 500], 'max_depth': [5, 20, 50]}, {'learning_rate': [0.02, 0.04, 0.06, 0.08], 'n_estimators': [300, 350, 400, 450, 500, 550], 'max_depth': [15, 16, 17, 18, 19, 20, 21, 22, 23, 24]}, {'learning_rate': [0.05, 0.060000000000000005, 0.07, 0.08000000000000002, 0.09000000000000001], 'n_estimators': [500, 550], 'max_depth': [14, 15, 16]}, {'learning_rate': [0.06, 0.06999999999999999, 0.07999999999999999, 0.08999999999999998, 0.09999999999999998], 'n_estimators': [600, 650], 'max_depth': [17, 18, 19, 20, 21]}, {'learning_rate': [0.07, 0.08, 0.09], 'n_estimators': [700, 750], 'max_depth': [18, 19, 20, 21]}, {'learning_rate': [0.07, 0.08, 0.09], 'n_estimators': [760, 780], 'max_depth': [19, 20, 21, 22]}, {'learning_rate': [0.07, 0.08, 0.09], 'n_estimators': [700, 710, 720, 730, 740, 750, 760, 770, 780, 790], 'max_depth': [20, 21, 22]}, {'learning_rate': [0.07, 0.08, 0.09], 'n_estimators': [740, 750, 760, 770, 780, 790], 'max_depth': [20, 21, 22]}, {'learning_rate': [0.07, 0.08], 'n_estimators': [765, 770, 775, 780, 785, 790, 795], 'max_depth': [22, 23, 24]}]\n",
      "\n",
      "        Best parameters: {'learning_rate': 0.07, 'max_depth': 22, 'n_estimators': 765}\n",
      "        RMSE: 0.06014580739471606\n",
      "        \n",
      "\n",
      "9th trial\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000291 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1838\n",
      "[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 2.071947\n",
      "\n",
      "[{'learning_rate': [0.01, 0.5, 1], 'n_estimators': [50, 250, 500], 'max_depth': [5, 20, 50]}, {'learning_rate': [0.02, 0.04, 0.06, 0.08], 'n_estimators': [300, 350, 400, 450, 500, 550], 'max_depth': [15, 16, 17, 18, 19, 20, 21, 22, 23, 24]}, {'learning_rate': [0.05, 0.060000000000000005, 0.07, 0.08000000000000002, 0.09000000000000001], 'n_estimators': [500, 550], 'max_depth': [14, 15, 16]}, {'learning_rate': [0.06, 0.06999999999999999, 0.07999999999999999, 0.08999999999999998, 0.09999999999999998], 'n_estimators': [600, 650], 'max_depth': [17, 18, 19, 20, 21]}, {'learning_rate': [0.07, 0.08, 0.09], 'n_estimators': [700, 750], 'max_depth': [18, 19, 20, 21]}, {'learning_rate': [0.07, 0.08, 0.09], 'n_estimators': [760, 780], 'max_depth': [19, 20, 21, 22]}, {'learning_rate': [0.07, 0.08, 0.09], 'n_estimators': [700, 710, 720, 730, 740, 750, 760, 770, 780, 790], 'max_depth': [20, 21, 22]}, {'learning_rate': [0.07, 0.08, 0.09], 'n_estimators': [740, 750, 760, 770, 780, 790], 'max_depth': [20, 21, 22]}, {'learning_rate': [0.07, 0.08], 'n_estimators': [765, 770, 775, 780, 785, 790, 795], 'max_depth': [22, 23, 24]}, {'learning_rate': [0.06, 0.06999999999999999, 0.07999999999999999], 'n_estimators': [760, 765, 770, 775, 780, 785, 790, 795], 'max_depth': [21, 22, 23, 24]}]\n",
      "\n",
      "        Best parameters: {'learning_rate': 0.07999999999999999, 'max_depth': 21, 'n_estimators': 760}\n",
      "        RMSE: 0.053796523950733484\n",
      "        \n",
      "\n",
      "10th trial\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000610 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1838\n",
      "[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 2.071947\n",
      "\n",
      "[{'learning_rate': [0.01, 0.5, 1], 'n_estimators': [50, 250, 500], 'max_depth': [5, 20, 50]}, {'learning_rate': [0.02, 0.04, 0.06, 0.08], 'n_estimators': [300, 350, 400, 450, 500, 550], 'max_depth': [15, 16, 17, 18, 19, 20, 21, 22, 23, 24]}, {'learning_rate': [0.05, 0.060000000000000005, 0.07, 0.08000000000000002, 0.09000000000000001], 'n_estimators': [500, 550], 'max_depth': [14, 15, 16]}, {'learning_rate': [0.06, 0.06999999999999999, 0.07999999999999999, 0.08999999999999998, 0.09999999999999998], 'n_estimators': [600, 650], 'max_depth': [17, 18, 19, 20, 21]}, {'learning_rate': [0.07, 0.08, 0.09], 'n_estimators': [700, 750], 'max_depth': [18, 19, 20, 21]}, {'learning_rate': [0.07, 0.08, 0.09], 'n_estimators': [760, 780], 'max_depth': [19, 20, 21, 22]}, {'learning_rate': [0.07, 0.08, 0.09], 'n_estimators': [700, 710, 720, 730, 740, 750, 760, 770, 780, 790], 'max_depth': [20, 21, 22]}, {'learning_rate': [0.07, 0.08, 0.09], 'n_estimators': [740, 750, 760, 770, 780, 790], 'max_depth': [20, 21, 22]}, {'learning_rate': [0.07, 0.08], 'n_estimators': [765, 770, 775, 780, 785, 790, 795], 'max_depth': [22, 23, 24]}, {'learning_rate': [0.06, 0.06999999999999999, 0.07999999999999999], 'n_estimators': [760, 765, 770, 775, 780, 785, 790, 795], 'max_depth': [21, 22, 23, 24]}, {'learning_rate': [0.07, 0.08, 0.09], 'n_estimators': [750, 760, 770, 780, 790], 'max_depth': [20, 21, 22, 23, 24]}]\n",
      "\n",
      "        Best parameters: {'learning_rate': 0.08, 'max_depth': 21, 'n_estimators': 760}\n",
      "        RMSE: 0.05379652395073347\n",
      "        \n",
      "\n"
     ]
    }
   ],
   "source": [
    "params_range_list_dict = {'learning_rate': [0.01, 0.5, 1], 'n_estimators': [50, 250, 500], 'max_depth': [5, 20, 50]}\n",
    "df_result = run_auto_tuning_lgbm(X_train,y_train,params_range_list_dict,max_try_count=20,early_stopping=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGBMRegressor(learning_rate=0.01, max_depth=20...</td>\n",
       "      <td>0.200514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LGBMRegressor(learning_rate=0.08, max_depth=16...</td>\n",
       "      <td>0.071131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LGBMRegressor(learning_rate=0.0800000000000000...</td>\n",
       "      <td>0.071131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LGBMRegressor(learning_rate=0.0799999999999999...</td>\n",
       "      <td>0.062309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LGBMRegressor(learning_rate=0.08, max_depth=18...</td>\n",
       "      <td>0.054782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LGBMRegressor(learning_rate=0.08, max_depth=21...</td>\n",
       "      <td>0.053797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LGBMRegressor(learning_rate=0.08, max_depth=21...</td>\n",
       "      <td>0.053797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LGBMRegressor(learning_rate=0.08, max_depth=21...</td>\n",
       "      <td>0.053797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LGBMRegressor(learning_rate=0.07, max_depth=22...</td>\n",
       "      <td>0.060146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LGBMRegressor(learning_rate=0.0799999999999999...</td>\n",
       "      <td>0.053797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LGBMRegressor(learning_rate=0.08, max_depth=21...</td>\n",
       "      <td>0.053797</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                model      RMSE\n",
       "0   LGBMRegressor(learning_rate=0.01, max_depth=20...  0.200514\n",
       "1   LGBMRegressor(learning_rate=0.08, max_depth=16...  0.071131\n",
       "2   LGBMRegressor(learning_rate=0.0800000000000000...  0.071131\n",
       "3   LGBMRegressor(learning_rate=0.0799999999999999...  0.062309\n",
       "4   LGBMRegressor(learning_rate=0.08, max_depth=18...  0.054782\n",
       "5   LGBMRegressor(learning_rate=0.08, max_depth=21...  0.053797\n",
       "6   LGBMRegressor(learning_rate=0.08, max_depth=21...  0.053797\n",
       "7   LGBMRegressor(learning_rate=0.08, max_depth=21...  0.053797\n",
       "8   LGBMRegressor(learning_rate=0.07, max_depth=22...  0.060146\n",
       "9   LGBMRegressor(learning_rate=0.0799999999999999...  0.053797\n",
       "10  LGBMRegressor(learning_rate=0.08, max_depth=21...  0.053797"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Auto_parameter_tuning_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
